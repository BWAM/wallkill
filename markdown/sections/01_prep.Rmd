---
title: "Untitled"
author: "Zachary M. Smith"
date: "4/24/2019"
output: html_document
---

```{r}
suppressPackageStartupMessages(
  library(tidyverse)
)
library(leaflet)
```

Establish file path to the project directory. This will be used to access data.
```{r}
project.path <- rprojroot::find_rstudio_root_file()
data.path <- file.path(project.path, "data", "2019-04-24")
```

# Data Preprocessing

## Functions

### clean_up

The `clean_up()` function is used to aid in the standardization of the data. The processes described below generally eliminate some of most common string features that can cause erroneous mismatching.

1. `tolower()`- all column names and character column values are converted to lower case strings. 
2. `trimws()` - leading and trailing whitespace is removed from all column names and character columns.
3. `gsub()`- more than one space is removed from strings in character columns.
```{r}
clean_up <- function(x) {
  names(x) <- tolower(names(x))
  names(x) <- trimws(names(x))
  
  final.df <- dplyr::mutate_if(x,
                               is.character,
                               list(~trimws(tolower(.))))  
  
  # remove instances of more than one space
  final.df <- dplyr::mutate_if(final.df,
                               is.character,
                               list(~gsub("[' ']{2,}", " ", .)))  
  
  final.df
}
```

## Stations

## Station Order

Zachary Smith ordered the Wallkill 2017 and 2018 samples from upstream to downstream relative to the mainstem Wallkill.
```{r}
station_order.df <- file.path(data.path, "finalized", "wallkill_station-order_up-to-down.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings=c(""," ","NA")) %>% 
  clean_up()
```

## Station Information

Import Wallkill 2017 and 2018 station information and combine these into a single data frame.
```{r}
sites17.df <- file.path(data.path, "WallkillSites2017.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings=c(""," ","NA")) %>% 
  clean_up() %>% 
  rename(site_id = sbu.id,
         survey = ras)

sites18.df <- file.path(data.path, "WallkillSites2018.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings=c(""," ","NA")) %>% 
  clean_up() %>% 
  rename(stream = name)

sites.df <- bind_rows(sites17.df, sites18.df) %>% 
  mutate(rivmile = gsub(".*-", "", site_id),
         location = gsub("-.*", "", site_id))
```

Clear the global environment of unnecessary objects.
```{r}
rm(sites17.df, sites18.df)
```

## BAP

Import Wallkill 2017 and 2018 BAP data and combine these into a single data frame.

1. Data processed with the `clean_up()` function.
2. Column name "location.station" changed to "station"
3. The `date` column is converted to a date class
4. The data is aggregated by `station` and `date`, and subsequently the mean and median BAP scores are calculated for these aggregates
5. __Stations "qker-0.9", "walk-35.6", and "wklei-0.6" were filtered out of the data frame because they were sampled as low gradient sites in 2018. These stations were sampled as kick-net samples in 2017. Both years are excluded.__
```{r}
bap.df <- c("WALLKILL2017_BAP.csv",
            "WALLKILL2018_BAP.csv") %>% 
  map_df(function(file.i) {
    file.path(data.path,
              file.i) %>% 
      read.csv(stringsAsFactors = FALSE,
               na.strings=c(""," ","NA"))
  }) %>% 
  clean_up() %>% 
  rename(station = location.station) %>% 
  mutate(rivmile = factor(rivmile, sort(unique(rivmile), decreasing = TRUE)),
         date = as.Date(date, "%m/%d/%Y")) %>% 
  group_by(station, date) %>% 
  mutate(mean_bap = mean(bap, na.rm = TRUE),
         median_bap = median(bap, na.rm = TRUE)) %>% 
  ungroup() %>% 
  filter(!station %in% c("qker-0.9",
                        "walk-35.6",
                        "wklei-0.6"))
```

The data is exported as a CSV and manually added to the Wallkill SharePoint "finalized" folder.
```{r}
data.table::fwrite(bap.df,
                   file.path(data.path,
                             "finalized",
                             "wallkill_bap_2017-2018.csv"))
```

# Chemistry

## Average Chemistry

Import the Wallkill average chemistry data.
```{r}
tp.df <- file.path(data.path,
                   "Wallkill_AVG_chem.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings=c(""," ","NA")) %>% 
  clean_up() %>% 
  rename(station = sbuid) %>% 
  select(station,
         tp_avg,
         tp_log10)
```

## 2017 and 2018 Chemistry

### Import

Import Wallkill 2017 Special study, 2018 RAS, and 2018 PEERS chemistry data. Perform general data standardization with the `clean_up()` function. The 2018 RAS data was QAQCed by Gavin Lemley (2019-04-29) using an R script developed by Alene Onion and Gavin Lemley. __However, the 2017 Special Study chemistry and the 2018 PEERS data have not been QAQCed.__
```{r}
chem2017.df <- file.path(data.path,
                         "2017_wallkill_chem_qaqcd-2019-04-29.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings = c(""," ","NA"),
           colClasses = c("fraction" = "character")) %>% 
  clean_up()

chem2018.df <- file.path(data.path,
                         "2018_wallkill_chem_qaqcd-2019-03-29.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings = c(""," ","NA"),
           colClasses = c("fraction" = "character")) %>% 
  clean_up() 

peers2018.df <- file.path(data.path,
                         "PEERS.wallkill.output.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings = c(""," ","NA"),
           colClasses = c("fraction" = "character")) %>% 
  clean_up()  %>% 
  mutate(fraction = "t")
```

### 2018 PEERS

We will only retain the columns present in the QAQCed 2018 RAS data. The script below identifies any columns present in the 2018 RAS data but missing in the 2018 PEERS data. We will want to add these columns to the 2018 PEERS data, if possible.
```{r}
names(chem2018.df)[!names(chem2018.df) %in% names(peers2018.df)]
```

"project_name" was the one of the columns which was present in the 2018 RAS data but absent from the 2018 PEERS data. The script below adds the column "project_name" to the 2018 PEERS data frame. The column is populated with the character string "wallkill peers 2018", which follows the labeling scheme found in the 2018 RAS data (i.e., wallkill ras 2018). 
```{r}
peers2018.df$project_name <- "wallkill peers 2018"
```

"siteid" is present in the 2018 RAS data but absent from the 2018 PEERS data. The script below adds the column "siteid" to the 2018 PEERS data frame. The column is populated by extracting the basin, location, and rivermile elements from "sys_sample_code", which follows the same pattern found in the 2018 RAS data.

The regex was difficult to solve. I found the answer to this stackoverflow question to be helpful (https://stackoverflow.com/questions/25448921/regex-to-extract-all-characters-before-the-second-dash-hyphen). The description below is modified from Casimir et Hippolyte answer in the link above.

1. \\A = anchor for the start of the string
2. (?: = open a non-capturing group
3. [^-]++  = all that is not an hyphen (possessive)
4. -?? = optional hyphen (lazy)
5. ){3} = repeat the group 3 times
```{r}
peers2018.df$siteid <- str_extract(peers2018.df$sys_sample_code, "\\A(?:[^-]++-??){3}")
```

Now that the 2018 PEERS data contains all of the columns present in the 2018 RAS data, the 2018 PEERS data is subset to only include columns that are found in the 2018 RAS data.
```{r}
peers2018.df <- peers2018.df[, names(peers2018.df) %in% names(chem2018.df)]
```

### Append

The Wallkill 2017 Special study, 2018 RAS, and 2018 PEERS chemistry data are combined into a single data frame.

1. Wallkill 2017 Special study, 2018 RAS, and 2018 PEERS chemistry data are appended together with `bind_rows()`
2. The "date" column is converted to the data time class "POSIXct"
3. "siteid" is renamed to "station"
4. The columns are re-ordered using `select()`
```{r}
chem.df <- bind_rows(chem2017.df, chem2018.df, peers2018.df) %>% 
  mutate(date_time = if_else(project_name == "wallkill peers 2018",
                             as.POSIXct(sample_date, "%Y-%m-%d", tz = "EST"),
                             as.POSIXct(sample_date, "%m/%d/%Y %H:%M", tz = "EST")),
         date_time = as.character(date_time)) %>% 
  rename(station = siteid) %>% 
  select(project_name, sys_sample_code, station, date_time, everything(), -sample_date)
```

The data is exported as a CSV and manually added to the Wallkill SharePoint "finalized" folder.
```{r}
data.table::fwrite(chem.df,
                   file.path(data.path,
                             "finalized",
                             "wallkill_chem_ras-2017-2018_peers-2018.csv"))
```

Clear the global environment of unnecessary objects.
```{r}
rm(chem2017.df, chem2018.df, peers2018.df)
```

## Field Data

### Import

Import Wallkill 2018 field data. Perform general data standardization with the `clean_up()` function. Convert the "coll_date_time" column to the calss POSIXct.
```{r}
field.df <- file.path(data.path,
                      "Wallkill_survey_Chem_Only.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings = c(""," ","NA")) %>% 
  clean_up() %>% 
  mutate(date_time = as.POSIXct(coll_date_time, format = "%m/%d/%Y %H:%M"))
```

### Preprocessing

This data frame is broken into three pieces (general information, ambient chemistry data, and user preception data) to make it easier to manipulate the data.

#### General Information

The code below checks to see if the column "y" has equivalent values to "field_lat and if "x" has equivalent values to "field_lon". These values are equivalent, and therefore "x" and "y" can be excluded from this data frame.
```{r}
any(field.df$field_lat != field.df$y | field.df$field_lon != field.df$x)
```

General field information is selected to represent this data frame.
```{r}
field_info.df <- field.df %>% 
  select(project, site_loc_id:descript, date_time,
         new_site, update_site,
         coll_date_time, crew, info_type, hablab_id_num,
         bloom_desc, bloom_desc_2, r_hablab_id, s_hablab_id,
         current_weather, past_weather,
         water_chem, qa_qc_type,
         samp_loc, equip_used,
         tox, 
         prim_contact, prim_variable, sec_contact, sec_variable,
         notes)
```

#### Ambient Chemistry Data

The ambient chemistry data, collected with a sonde, is transformed to a long data format. The column "data_type" is added to indicate that values in these rows are represent the ambient chemistry data.
```{r}
field_chem.df <- field.df %>% 
  select(project, site_loc_id, date_time,
         temp:salinity) %>% 
  gather(param, value, temp:salinity) %>% 
  mutate(data_type = "amb_chem")
```

#### User Preception Data

The user preception data is transformed to a long data format. The column "data_type" is added to indicate that values in these rows are represent the user preception data.
```{r}
field_precep.df <- field.df %>% 
  select(project, site_loc_id, date_time,
         water_clarity:discharge_pipes) %>% 
  gather(param, value, water_clarity:discharge_pipes) %>% 
  mutate(data_type = "user_preception")
```

#### Combine the Data

Append the ambient chemistry and user preception data into a single data frame. Again, the "data_type" column can be used to distinquish between these two sets of data.
```{r}
field_values.df <- bind_rows(field_chem.df, field_precep.df)
```

The `field_values.df` data frame is joined with the general field info.
```{r}
field_final.df <- full_join(field_info.df, field_values.df, by = c("project", "site_loc_id", "date_time"))
```

The data is exported as a CSV and manually added to the Wallkill SharePoint "finalized" folder.
```{r}
data.table::fwrite(field_final.df ,
                   file.path(data.path,
                             "finalized",
                             "wallkill_field_2018.csv"))
```

Clear the global environment of unnecessary objects.
```{r}
rm(field.df, field_info.df, field_chem.df, field_precep.df, field_values.df)
```
