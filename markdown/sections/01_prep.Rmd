---
title: "Untitled"
author: "Zachary M. Smith"
date: "4/24/2019"
output: html_document
---

```{r}
suppressPackageStartupMessages(
  library(tidyverse)
)
library(leaflet)
```

Establish file path to the project directory. This will be used to access data.
```{r}
project.path <- rprojroot::find_rstudio_root_file()
data.path <- file.path(project.path, "data", "2019-04-30")
```

# Data Preprocessing

## Functions

### clean_up

The `clean_up()` function is used to aid in the standardization of the data. The processes described below generally eliminate some of most common string features that can cause erroneous mismatching.

1. `tolower()`- all column names and character column values are converted to lower case strings. 
2. `trimws()` - leading and trailing whitespace is removed from all column names and character columns.
3. `gsub()`- more than one space is removed from strings in character columns.
```{r}
clean_up <- function(x) {
  names(x) <- tolower(names(x))
  names(x) <- trimws(names(x))
  
  final.df <- dplyr::mutate_if(x,
                               is.character,
                               list(~trimws(tolower(.))))  
  
  # remove instances of more than one space
  final.df <- dplyr::mutate_if(final.df,
                               is.character,
                               list(~gsub("[' ']{2,}", " ", .)))  
  
  final.df
}
```

## Stations

On 4/30/2019, A.J. Smith suggested that we drop stations sampled for HABs monitoring (i.e., "13-gunk-40.3", "13-gunk-t35-0.2", "13-gunk-37.7", and "13-lgun-6.0").
```{r}
ex.station.vec <- c("13-gunk-40.3",
                    "13-gunk_t35-0.2",
                    "13-gunk-37.7",
                    "13-lgun-6.0")
```

### Station Information

Import Wallkill 2017 and 2018 station information and combine these into a single data frame. 2018 special study station "13-walk-0.8" is considered equivalent to "13-walk-0.7", and therefore is relabeled as "13-walk-0.8".
```{r}
stations17.df <- file.path(data.path,
                           "sites",
                           "WallkillSites2017.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings=c(""," ","NA")) %>% 
  clean_up() %>% 
  rename(station = sbu.id,
         survey = ras)

stations18.df <- file.path(data.path,
                           "sites",
                           "WallkillSites2018.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings=c(""," ","NA")) %>% 
  clean_up() %>% 
  rename(station = site_id,
         stream = name) %>% 
  mutate(station = if_else(station %in% "13-walk-0.8", "13-walk-0.7", station))

stations.df <- bind_rows(stations17.df, stations18.df) %>% 
  mutate(rivmile = gsub(".*-", "", station),
         location = gsub("-.*", "", station),
         station = paste("13", station, sep = "-")) %>% 
  filter(!station %in% ex.station.vec)
```

Clear the global environment of unnecessary objects.
```{r}
rm(stations17.df, stations18.df)
```

### PEERS Stations

Import 2018 PEERS stations collected within the Wallkill basin.
```{r}
stations_peers.df <- file.path(data.path,
                           "peers",
                           "peers_stations.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings=c(""," ","NA")) %>% 
  clean_up() %>% 
  select(station, latitude, longitude) %>% 
  mutate(type = "peers")
```

Add the PEERS stations to the `stations.df` data frame.
```{r}
stations.df <- bind_rows(stations.df, stations_peers.df) 
```

### Gage Stations

Import USGS gage stations found within the Wallkill basin.
```{r}
gage.df <- file.path(data.path,
                           "gage",
                           "GageSites.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings=c(""," ","NA")) %>% 
  clean_up() %>% 
  mutate(type = "gage")
```

Add the gaged stations to the `stations.df` data frame.
```{r}
stations.df <- bind_rows(stations.df, gage.df)  %>% 
  mutate(gage = if_else(type %in% "gage", TRUE, FALSE))
```

### Station Order

Zachary Smith ordered the Wallkill 2017 and 2018 samples from upstream to downstream relative to the mainstem Wallkill.
```{r}
station_order.df <- file.path(data.path,
                              "finalized",
                              "wallkill_station-order_up-to-down.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings=c(""," ","NA")) %>% 
  clean_up() %>% 
  filter(!station %in% ex.station.vec)
```

```{r}
stations.df <- left_join(station_order.df, stations.df, by = "station")
```

## BAP

Import Wallkill 2017 and 2018 BAP data and combine these into a single data frame.

1. Data processed with the `clean_up()` function.
2. Column name "location.station" changed to "station"
3. The `date` column is converted to a date class
4. The data is aggregated by `station` and `date`, and subsequently the mean and median BAP scores are calculated for these aggregates
5. __Stations "qker-0.9", "walk-35.6", and "wklei-0.6" were filtered out of the data frame because they were sampled as low gradient sites in 2018. These stations were sampled as kick-net samples in 2017. Both years are excluded.__
```{r}
bap.df <- c("WALLKILL2017_BAP.csv",
            "WALLKILL2018_BAP.csv") %>% 
  map_df(function(file.i) {
    file.path(data.path,
              "bap",
              file.i) %>% 
      read.csv(stringsAsFactors = FALSE,
               na.strings=c(""," ","NA"))
  }) %>% 
  clean_up() %>% 
  rename(station = location.station) %>% 
  mutate(station = paste("13", station, sep = "-"),
         rivmile = factor(rivmile, sort(unique(rivmile), decreasing = TRUE)),
         date = as.Date(date, "%m/%d/%Y")) %>% 
  group_by(station, date) %>% 
  mutate(replicates = n(),
         mean_bap = mean(bap, na.rm = TRUE),
         median_bap = median(bap, na.rm = TRUE)) %>% 
  ungroup() %>% 
  filter(!station %in% c("qker-0.9",
                        "walk-35.6",
                        "wklei-0.6"),
         !station %in% ex.station.vec)
```

The data is exported as a CSV and manually added to the Wallkill SharePoint "finalized" folder.
```{r}
data.table::fwrite(bap.df,
                   file.path(data.path,
                             "finalized",
                             "wallkill_bap_2017-2018.csv"))
```

# Chemistry

## Average Chemistry

Import the Wallkill average chemistry data.
```{r}
tp.df <- file.path(data.path,
                   "chemistry",
                   "Wallkill_AVG_chem.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings=c(""," ","NA")) %>% 
  clean_up() %>% 
  rename(station = sbuid) %>% 
  select(station,
         tp_avg,
         tp_log10)
```

## 2017 and 2018 Chemistry

### Import

Import Wallkill 2017 and 2018 Special Studies and 2018 PEERS chemistry data. Perform general data standardization with the `clean_up()` function. The 2018 Special Study data was QAQCed by Gavin Lemley (2019-04-29) using an R script developed by Alene Onion and Gavin Lemley. __However, the 2017 Special Study chemistry and the 2018 PEERS data have not been QAQCed.__ 
```{r}
chem2017.df <- file.path(data.path,
                         "chemistry",
                         "2017_wallkill_chem_qaqcd-2019-04-29.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings = c(""," ","NA"),
           colClasses = c("fraction" = "character")) %>% 
  clean_up()

chem2018.df <- file.path(data.path,
                         "chemistry",
                         "2018_wallkill_chem_qaqcd-2019-03-29.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings = c(""," ","NA"),
           colClasses = c("fraction" = "character")) %>% 
  clean_up() %>% 
  mutate(project_name = "wallkill special study 2018")

peers2018.df <- file.path(data.path,
                          "peers",
                         "PEERS.wallkill.output.site.names.fixed.csv") %>% 
  read.csv(stringsAsFactors = FALSE,
           na.strings = c(""," ","NA"),
           colClasses = c("fraction" = "character")) %>% 
  clean_up()  %>% 
  mutate(fraction = "t")
```

### 2018 PEERS

We will only retain the columns present in the QAQCed 2018 Special Study data. The script below identifies any columns present in the 2018 Special Study data but missing in the 2018 PEERS data. We will want to add these columns to the 2018 PEERS data, if possible.
```{r}
names(chem2018.df)[!names(chem2018.df) %in% names(peers2018.df)]
```

"project_name" was the one of the columns which was present in the 2018 Special Study data but absent from the 2018 PEERS data. The script below adds the column "project_name" to the 2018 PEERS data frame. The column is populated with the character string "wallkill peers 2018", which follows the labeling scheme found in the 2018 Special Study data (i.e., wallkill special study 2018). 
```{r}
peers2018.df$project_name <- "wallkill peers 2018"
```

"siteid" is present in the 2018 Special Study data but absent from the 2018 PEERS data. The script below adds the column "siteid" to the 2018 PEERS data frame. The column is populated by extracting the basin, location, and rivermile elements from "sys_sample_code", which follows the same pattern found in the 2018 Special Study data.

The regex was difficult to solve. I found the answer to this stackoverflow question to be helpful (https://stackoverflow.com/questions/25448921/regex-to-extract-all-characters-before-the-second-dash-hyphen). The description below is modified from Casimir et Hippolyte answer in the link above.

1. \\A = anchor for the start of the string
2. (?: = open a non-capturing group
3. [^-]++  = all that is not an hyphen (possessive)
4. -?? = optional hyphen (lazy)
5. ){3} = repeat the group 3 times
```{r}
peers2018.df$siteid <- str_extract(peers2018.df$sys_sample_code,
                                   "\\A(?:[^-]++-??){3}")
```

Now that the 2018 PEERS data contains all of the columns present in the 2018 RAS data, the 2018 PEERS data is subset to only include columns that are found in the 2018 RAS data.
```{r}
peers2018.df <- peers2018.df[, names(peers2018.df) %in% names(chem2018.df)]
```

### Append

The Wallkill 2017 and 2018 Special Studies and 2018 PEERS chemistry data are combined into a single data frame.

1. Wallkill 2017 and 2018 Special Studies and 2018 PEERS chemistry data are appended together with `bind_rows()`
2. The "date" column is converted to the data time class "POSIXct"
3. "siteid" is renamed to "station"
4. The columns are re-ordered using `select()`
5. 2018 special study station "13-walk-0.8" is considered equivalent to "13-walk-0.7", and therefore is relabeled as "13-walk-0.8".
```{r}
chem.df <- bind_rows(chem2017.df, chem2018.df, peers2018.df) %>% 
  mutate(date_time = if_else(project_name == "wallkill peers 2018",
                             as.POSIXct(sample_date, "%m/%d/%Y", tz = "EST"),
                             as.POSIXct(sample_date, "%Y-%m-%d %H:%M:%S", tz = "EST")),
         date_time = as.character(date_time)) %>% 
  rename(station = siteid) %>% 
  select(project_name, sys_sample_code, station,
         date_time, everything(), -sample_date) %>% 
  filter(!station %in% ex.station.vec) %>% 
  mutate(station = if_else(station %in% "13-walk-0.8", "13-walk-0.7", station))
```

The data is exported as a CSV and manually added to the Wallkill SharePoint "finalized" folder.
```{r}
data.table::fwrite(chem.df,
                   file.path(data.path,
                             "finalized",
                             "wallkill_chem_ras-2017-2018_peers-2018.csv"))
```

Clear the global environment of unnecessary objects.
```{r}
rm(chem2017.df, chem2018.df, peers2018.df)
```


